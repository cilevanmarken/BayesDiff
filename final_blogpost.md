# BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference

### *Ivo Brink, Cile van Marken, Sebastiaan Snel, Liang Telkamp, Jesse Wiers*

*May 2024*

---

In this blogpost, we discuss our findings on enhancing the quality of images generated by diffusion models, by incorporating pixel-wise uncertainty estimation through Bayesian inference. This involves reproducing the research of the paper "BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference" by Kou, Gan, Wang, Li, and Deng (2024) plus an ablation study to test their claims regarding their Bayesian implementation. The BayesDiff paper discusses the effectiveness of diffusion models (DMs) in transforming noise vectors into natural images across various applications, such as image synthesis and text-to-image generation. Despite their capabilities, these models often produce unrealistic artifacts, such as structural inconsistencies, leading to poor image quality. This emphasizes the need for an accurate evaluation metric to detect poorly generated image samples.

The BayesDiff paper acknowledges this challenge of filtering out low-quality images due to the lack of a reliable metric for assessing image quality. An often-used evaluation metric is the FrÃ©chet Inception Distance (FID), which falls short of capturing aspects of image quality the way humans do [Jayasumana et al., 2024]. The authors aim to address these shortcomings by introducing pixel-wise uncertainty, which can be used in identifying and potentially discarding the most uncertain images, or to improve generated images by enhancing the diversity or rectifying artifacts in the generated samples.


<table align="center">
  <tr align="center">
      <td><img src="https://github.com/cilevanmarken/BayesDiff/raw/main/images/Uncertainty_maps.png" width=600></td>
  </tr>
  <tr align="left">
    <td colspan=2><b>Figure 1.</b> Visualization of the pixel-wise uncertainty from the BayesDiff paper</td>
  </tr>
</table>


How do diffusion models work?
Diffusion Models (DMs) are a family of probabilistic generative models that progressively destruct data by injecting noise (forward process), and then learn to reverse this process by denoising the data to generate new samples (backward process) [Yang et al., 2023]. There exists many variants of diffusion models and in the Bayesdiff paper Diffusion Denoising Probabilistic Models (DDPMs) are used [Ho et al., 2020] and models built upon it including Guided Diffusion, Stable Diffusion and Adversarial Diffusion Models (ADMs). In this section we will explain the method behind DDPMs. 
In diffusion models, the forward process, parameterized by ð‘ž in equation [1] uses data points ð‘¥0âˆ¼ð‘ž(ð‘¥), sampled from a real data distribution in which a small amount of Gaussian noise, with a variance of ð›½ð‘¡âˆˆ(0,1), is added in ð‘‡ steps. This results in a sequence of noisy samples ð‘¥1,...,ð‘¥ð‘‡ parameterized by the equation [1].
ð‘ž(ð‘¥1,â€¦,ð‘¥ð‘‡âˆ£ð‘¥0):=âˆð‘¡=1ð‘‡ð‘ž(ð‘¥ð‘¡âˆ£ð‘¥ð‘¡âˆ’1)ð‘ž(ð‘¥ð‘¡âˆ£ð‘¥ð‘¡âˆ’1):=ð‘(ð‘¥ð‘¡;1âˆ’ð›½ð‘¡ð‘¥ð‘¡âˆ’1,ð›½ð‘¡ð¼)     [equation 1]
As ð‘¡ (t \in T) becomes larger the data sample ð‘¥0 gradually loses its distinguishable features and becomes equivalent to an isotropic Gaussian distribution. Figure 2 illustrates both the forward diffusion process that gradually adds noise to the image and the reversed process. In this reversed process, the true noise sample from a Gaussian noise input ð‘¥ð‘‡âˆ¼ð‘(0,ð¼) is recreated by sampling from ð‘ž(ð‘¥ð‘¡âˆ’1|ð‘¥ð‘¡). What the model learns is the reversed process ð‘ðœƒ, parameterized by equation [2].
ð‘ðœƒ(ð‘¥ð‘¡âˆ’1âˆ£ð‘¥ð‘¡):=ð‘( ð‘¥ð‘¡âˆ’1;ðœ‡ðœƒ(ð‘¥ð‘¡,ð‘¡),Î£ðœƒ(ð‘¥ð‘¡,ð‘¡))           [equation 2]
Here ðœ‡ðœƒ and Î£ðœƒ refer to the mean predictor and covariance predictor respectively. Instead of predicting the mean of the distribution in equation 2, in reality a noise predictor network, ÏµÎ¸, predicts the noise component at step t, a linear combination of xt and this noise component than forms the mean. The noise predictor network is trained by minimizing: 

 
The BayesDiff paper utilizes different types of Diffusion models. However, in our reproduction we focus on DPPMs and Guided Diffusion. Guided Diffusion enhances upon DDPMs by incorporating additional guidance during the sampling process, allowing to steer the sampling process to generate samples belonging to a specific class. 

Figure 2. The Markov chain of forward (and reverse) diffusion process (DDPM) [Ho et al. 2020].









Building upon DDPMs, Song et al. (2020) propose an alternative sampling method in their method: Denoising Diffusion Implicit Models (DDIMs). DDIMs provide a more efficient class of iterative implicit probabilistic models with the same training procedure as DDPMs. DDIM sampling yields an equal marginal noise distribution. However, deterministically maps noise back to the original data samples. This allows the model to train for an arbitrary number of forward steps, while allowing sampling from only a specific subset of these steps, during the generative process. DDIM sampling yields the following advantages:
The ability to generate higher-quality samples using fewer steps.
Because the generative process is deterministic it yields the â€œconsistencyâ€ property. This means that multiple samples conditioned on the same latent variable should have similar high-level features.
Because of the "consistency" property, DDIM can do semantically meaningful interpolation in the latent variable.
In conducting the research of this blogpost we utilize DDPM with the DDIM sampling. Despite the improvements in DMs, challenges such as uncertainty in generated images and the presence of artifacts persist. To address these issues, Bayesian inference can be utilized in enhancing the robustness and reliability of DMs by estimating pixel-wise uncertainty for assessing the quality of generated images.





















What is the role of Bayesian inference here?
Bayesian inference can be used for uncertainty quantification in Diffusion Models by turning a deterministic neural network into a Bayesian Neural Network (BNN). The Bayesian approach that is used in the BayesDiff paper is the Last Layer Laplace Approximation (LLLA) [Daxberger et al., 2022]. 
We define the likelihood as the probability of observing the noise $\boldsymbol{\epsilon}_t$ given the noisy image $\boldsymbol{x}_t$ and the model parameters $\Theta$. This can be modeled by a Gaussian:
$p(\boldsymbol{\epsilon}_t | f(\boldsymbol{x}_t ; \Theta) ) = \mathcal{N}(\boldsymbol{\epsilon}_t | f(\boldsymbol{x}_t ; \Theta), \sigma^2 \: I_{HWC \times HWC})$,
where $f(\boldsymbol{x}_t;\Theta)$ is the mean of the distribution representing the predicted noise of the model. $\sigma$ represents the variance of the noise. Larger values will regularize the model by making it more robust against noise, whereas lower values increase the influence of noise on the model's predictions. 
Likewise we define the prior over the weights by the following normal:
$p(\Theta) = \mathcal{N} \big( \Theta | \boldsymbol{0}, \gamma^2 \: I\big)$
With this prior we regularize the model by forcing the weights to be centered around 0. The $\gamma$ represents the variance on the weights.
The real posterior $p(\Theta | D)$ is known to be intractable. We thus make use of an approximation in order to find an appropriate distribution over our weights, e.g., $q(\Theta | D).$
# Last Layer Laplace Approximation (LLLA)
One of those approximations is the last layer Laplace approximation. The Last Layer Laplace Approximation aims to find a Gaussian approximation to the predictive posterior over the weights of the last layer MAP estimate $\Theta_{MAP}$ of a model, while assuming the previous layers to be fixed. Defined by equation \[x]:
$q(\Theta | D) = \mathcal{N}(\Theta | \Theta_{MAP}, \Sigma)$
The $\Theta_{MAP}$ are the weights that maximize the posterior distribution, e.g., the pre-trained weights of a diffusion model. The $\Sigma$, however, is the inverse Hessian that must still be computed \[Kristiadi et al., 2020]. The Hessian matrix calculated at the MAP estimate is depicted in equation \[x].
$\nabla_{\Theta}^2 \mathcal{L}(\mathcal{D} ; \Theta) \bigg|_{\Theta = \Theta_{MAP}} = - \gamma^{-2} I - \sum_{n=1}^N \nabla_{\Theta}^2 \; \log p\big(\boldsymbol{\epsilon}_{t, n} | f(\boldsymbol{x}_{t,n} ; \Theta) \big) \bigg|_{\Theta = \Theta_{MAP}}$
Clearly, this Hessian is influenced by $\gamma$ and the Gaussian Log Likelihood. As mentioned before, the $\sigma$ defines the variance of the model's predictions in the likelihood. Consequently, this raises a vital question. How are these tuning parameters, $\gamma$ and $\sigma$ determined in the original work? We will tackle this in our ablation study later on.
The Hessian describes the local curvature around the MAP estimate, and its inverse is therefore a good measure of variance for our approximate distribution. However, the Hessian can become too large to compute, due to the complexity of an entire covariance matrix of all pixels in an image. To circumvent this issue, the authors make use of a diagonal approximation of the Hessian, which ignores all off-diagonal elements, assuming strong pixel independence.
A Monte Carlo method is adopted to approximate the variance in the output. The method samples 100 images with different weights drawn from our approximated distribution, much like an ensemble method. The variance and expected values may be derived from the generated samples. The variance will be the final pixel-wise uncertainty that drives this research.
Hessian-free Laplace
The Hessian is the computational bottleneck of LLLA, which is the step of calculating and inverting the Hessian matrix ð» of the log posterior. Recent research, such as the work by Zhdanov et al. (2024) highlights that focusing on optimizing the prior precision alone can yield comparable or even superior results in uncertainty estimation and OOD detection, without the need for explicit Hessian computations.

The proposed approach simplifies the Laplace approximation by replacing the diagonal Hessian with the diagonal of the identity matrix scaled by the prior precision. The authors [BRON] redefine the covariance matrix as:Î£ðœƒ=ðœ†ð¼where $\lambda $ is the optimized prior precision. This adjustment modifies the posterior approximation to:
ð‘(ðœƒ|ð·)â‰ˆð‘(ðœƒMAP,ðœ†âˆ’1ð¼)
Here, ðœ†ð¼ represents the prior precision matrix.
Bypassing the Hessian might eliminate the need for the skip model and allow uncertainties to be calculated at every step to improve uncertainty estimates. This method presents an alternative to  maintain or even enhance uncertainty estimates without the computational burden of the Hessian approximation.
How do we evaluate Diffusion Models?
The authors make use of the Frechet Inception Distance (FID) to quantify their results. Despite its widespread use in the domain of image generation, the FID may perform differently from the gold standard, human raters [Jayasumana et al., 2024] by categorizing unrealistic or malformed images as qualitative. Therefore, this research proposes to evaluate the images with an additional evaluation metric, namely CLIP embeddings Maximum Mean Discrepancy (CMMD). As a means to motivate this choice, we explain both metrics:
FID
The FrÃ©chet inception distance (FID) is a widely used evaluation metric for assessing the quality of generated images compared to real ones [Heusel et al., 2018]. It quantifies the dissimilarity between the distributions of features extracted from real images and those generated by an algorithm. Let us examine the key components of the FID, where ð‘š and ð‘šð‘¤ are the means of the feature representations of the real and generated images respectively, ð¶ and ð¶ð‘¤ are the covariance matrices of the feature representations of the real and generated images.
ð‘‘2((ð‘š,ð¶),(ð‘šð‘¤,ð¶ð‘¤))=||ð‘šâˆ’ð‘šð‘¤||22+Tr(ð¶+ð¶ð‘¤âˆ’2(ð¶ð¶ð‘¤)1/2) [equation 5]
Recent research has highlighted the limitations of the FID, particularly its inconsistency with human perception in certain cases. For instance, the FID may inaccurately assess image quality under progressive distortions, leading to misleading results [Jayasumana et al., 2024]. Figure 4 emphasizes their main findings in which the FID does not reflect progressive distortion applied to images. To address these shortcomings Jayasuma et al. propose a different metric named CMMD. A disadvantage of the FID compared to CMMD is that the FID has a bias that is dependent on the number of images that is being evaluated, to the extent that the sample size can lead to different rankings of the models being evaluated. In contrast to the FID, the CMMD metric is unbiased.

Figure 8. Behavior of FID and CMMD under different sample sizes. Absolute values of the metrics [Jayasumana et al., 2024]
CMMD
Due to the usage of CLIP embeddings CMMD is a metric that is less dependent on sample size than FID. Given the sample size for image evaluation due to limited resources in our research, CMMD might be the best metric. Jayasumana et al. propose a new metric to evaluate image generation models, using CLIP embeddings and the Maximum Mean Discrepancy (MMD) distance, with a Gaussian RBF kernel. The CMMD (CLIP-MMD) metric is the squared MMD distance between CLIP embeddings of the reference (real) image set and the generated image set. CLIP embeddings are better suited for complex content such as images, because it trains an image encoder and a text encoder jointly using 400 million image-text pairs containing complex scenes. To compute the CMMD [Jayasumana et al., 2024], the Maximum Mean Discrepancy (MMD) between the CLIP embeddings has to be obtained which is denoted by:
ð‘‘ð‘–ð‘ ð‘¡ð‘€ð‘€ð·2(ð‘ƒ,ð‘„)=ð¸ð‘¥,ð‘¥â€²[ð‘˜(ð‘¥,ð‘¥â€²)]+ð¸ð‘¦,ð‘¦â€²[ð‘˜(ð‘¦,ð‘¦â€²)]âˆ’2ð¸ð‘¥,ð‘¦[ð‘˜(ð‘¥,ð‘¦)]ð‘˜(ð‘¥,ð‘¦)=ð‘’ð‘¥ð‘(âˆ’||ð‘¥âˆ’ð‘¦||2/2ðœŽ2)
where ð‘¥ and ð‘¥â€² are independently distributed by ð‘ƒ and ð‘¦ and ð‘¦â€² are independently distributed by ð‘„. Furthermore, the MMD kernel is denoted by ð‘˜(ð‘¥,ð‘¦).




We evaluate the performance by generating 5,000 images, following the guidelines from "Rethinking FID," which indicate that the CMMD score stabilizes with this number of images. It is crucial to note that for CMMD, the number of generated images should equal the number of reference images used to calculate the distance.
We also evaluate the models using the FID score. While we lack the computational resources to generate over 20,000 images for a more extensive FID analysis, the FID score can still be used for comparison purposes.
Aggregation methods lead to a reduction in the number of images, which can affect both the CMMD and FID scores. To ensure a fair comparison among the aggregation methods, we randomly select 4,400 images and compute the CMMD and FID scores for this subset. This approach helps to soften the impact of image loss due to aggregation on the evaluation metrics.

Reproduction of the experiments
Now that we are acquainted with the theory behind the research, it is time to try to reproduce the BayesDiff paper. The BayesDiff paper utilizes five different DMs (DDPM, Guided Diffusion, Stable Diffusion, U-ViT and ADM) and two different sampling methods (the DDIM sampler and DPM-solver). For reproduction, we focused on the Guided diffusion and DDPM model in combination with the DDIM sampler. 
We performed the experiments using the CelebA and ImageNet datasets. The CelebA dataset (CelebFaces Attributes Dataset) [Yang et al., 2015] contains more than 200.000 images (image quality: 64x64) with the faces of celebrities. ImageNet consists of over 1 million images in 1000 different classes [Deng et al., 2009].
High vs low uncertainty images

Figure X: high vs low uncertainty images, generated using DDPM with a DDIM sampler, for ImageNet and CelebA.

Figure X illustrates the four images with the highest and the lowest uncertainty, out of 80 generated images using a DDPM model and DDIM sampler for ImageNet and CelebA. The results are in line with the BayesDiff paper, where the authors indicate that their image-wise uncertainty metric is â€˜likely to indicate the level of clutter and the degree of subject prominence in the imageâ€™. Additionally, they note that their measure can thus be used to detect low-quality images. 

A point of critique is that the images with a higher uncertainty seem to exhibit more detail, while the images with a lower uncertainty seem to be more bland or have a blurred background. Additionally, the degree of subject prominence does not seem to change between images of high and low uncertainty, leading us to question if this metric is as useful as the authors claim it to be.
Visualizing uncertainty maps

Figure X: Visualization of the pixel-wise uncertainty for generations on CelebA using DDPM with a DDIM sampler from the BayesDiff paper (left) and our own (right). 

To intuitively better understand how the BayesDiff pixel-wise uncertainty works, the authors visualized the uncertainty maps. The pixel-wise uncertainty is defined as the variance. Pixels with higher variance are more unstable and thus more uncertain, which is indicated by a lighter color on the uncertainty map.

Our uncertainty maps are overall consistent with those presented in the BayesDiff paper: we observe more uncertainty around facial features, such as the eyes and mouth. However, there are differences between the uncertainty maps, despite them being generated with the same specifications. Our uncertainty maps seem to contain more noise, with a larger contrast between certain and uncertain pixels.
Low-quality image filtering
The authors have introduced the BayesDiff framework as a method to filter out low-quality generations. They demonstrate that the distribution of the summed uncertainty of a set of 50,000 generated images approximately follows a normal distribution, as illustrated in Figure X. Outliers can thus be filtered by eliminating images with an uncertainty higher than . The authors test the effectiveness of their filter method by comparing the FID scores of the set of the full set of generated images with the set of filtered images.


Figure X: The empirical distribution of the uncertainty estimates of the BayesDiff paper (left) and of our generated images (right).

To reproduce the results, we have generated 5,024 images. When plotting the summed uncertainty values, we observed a distribution similar to a normal distribution, though slightly skewed. This skewness could be due to our sample size being one-tenth of the authors' sample. This limited sample size is due to limited computation and memory resources.

We compare the FID scores of 1) the set of our generated images, 2) the set of filtered images, and 3) the set of generated images from which the same number of images as in set 2 were removed at random.

The results are presented and will be discussed in Our contributions > Results.


Our contribution
Hyperparameter search
Before we can extend the Bayesian approach to uncertainty in generated images, it is essential to determine whether the Bayesian approach is viable. One way to test the Bayesian approach is by changing the parameters of the Last Layer Laplacian Approximation (LLLA). As mentioned before, the tuning parameters $\sigma$ and $\gamma$ need to be set. Adjusting these parameters leads to different approximations of the Hessian, and thus different distributions of our last layer weights. So, this should result in varying uncertainty maps given a well-functioning Bayesian implementation.
Two hyperparameters that influence the LLLA are the prior precision ($\gamma$) and the sigma noise ($\sigma$):
The prior precision (equation X) indicates how strongly we believe in our prior knowledge about the generated images. A strong prior results in a narrower posterior distribution, meaning the model is more certain about its generated pixel-wise values. When generating uncertainty maps with a high prior precision, we would expect the maps to be darker compared to those generated with a low prior precision, as the model should be more certain about its generations.
The sigma noise (equation X) represents the standard deviation of the noise in the data. A high sigma noise corresponds to noisier data, making the model more uncertain about the generated images. Therefore, images generated with a high sigma noise should result in lighter uncertainty maps, while those with a low sigma noise should result in darker uncertainty maps.
The authors have fixed the parameters for the prior precision and the sigma noise of the LLLA to 1.0 and 1.0, respectively. However, they have not specified their motivation for this. We conducted a hyperparameter search with the following values:
Prior precision in range from 0 to 1000.
Sigma noise between 0 and 1.
The resulting uncertainty maps are illustrated in Appendix A for the DDPM model with the DDIM sampler for ImageNet and CelebA. For CelebA, the uncertainty maps behave as expected: higher prior precision indicates a higher certainty, and indeed the uncertainty maps are darker for higher values of prior precision. Higher values for the sigma noise also result in darker uncertainty maps, as expected. 
However, when running the same experiment for ImageNet, the uncertainty maps do not seem to change. So far we have not been able to pinpoint why this is the case: the codebase is the same for both ImageNet and CelebA, although the diffusion backbone is different. This discrepancy suggests that the BayesDiff codebase may have issues. 
Aggregation methods
Another point of interest is the aggregation method used by the authors. They currently sum the pixel-wise uncertainties to determine the uncertainty value per image, which is then used to filter out low-quality images. However, this aggregation method might not fully capture the significance of different image regions in assessing overall uncertainty. For instance, an image with uniformly moderate uncertainty across all pixels would yield an equivalent score as an image characterized by highly certain and highly uncertain regions. Furthermore, this method does not differentiate between the object of interest and the background.
To address these issues, we propose two novel aggregation methods: PatchMax and SegmentationMean.
PatchMax: This method involves subdividing the image into 4x4 patches. We calculate the mean pixel uncertainty for each patch and then select the maximum uncertainty among all patches as the final score. This method ensures that areas of high uncertainty are accentuated, which may be critical in assessing image quality.
SegmentationMean: Leveraging a segmentation model, specifically the pre-trained DeepLabV3 with a ResNet-50 backbone [Chen et al., 2017], this method applies a mask to exclude background uncertainties. The mean uncertainty of the remaining pixels is used as the final score. This method highlights uncertainty within primary objects and neglects uncertainties in complex and cluttered backgrounds. 

Figure X: The empirical distribution of the uncertainty estimates of the aggregation methods Sum, PatchMax, and SegmentationMean.

Figure X illustrates that all aggregation methods roughly follow a (slightly skewed) Gaussian distribution, which indicates that we may remove outliers by removing the images with an uncertainty higher than . The results are illustrated and discussed in the Results section.
Hessian Free Laplacian
We tested the Hessian-free variant using different values of prior precision, which resulted in varying uncertainty maps. Higher precision values produced more confident (darker) uncertainty maps. We selected a prior precision of 3, as it revealed some facial contours in the uncertainty maps and generated reasonable images, comparable to those from the normal and adversarial variants.


Results

Aggregation
Bayesdiff (1,1)
Adversarial (0.001, 1000)
Hessianfree (1,3)
Bayesdiff (1,1)
Adversarial (0.001, 1000)
Hessianfree (1,3)
Eval metric
CMMD \downarrow
FID  \downarrow
None
1.739
1.708
1.7879
62.525
83.726
56.256
Sum
1.744 (4376)
 1.718
(4207)
1.7772 
(4355)
64.866
84.567
57.184
PatchMZ
1.739 (4475)
 1.707
(4405)
1.7798
(4414)
65.174
84.304
57.351
SegmentationMean
1.747 (4384)
1.711
(4265)
1.78
 (4323)
64.25
85.082
56.924
random (4400)
1.729
1.698
1.7846
62.705
85.339
56.4681

Table 1: Evaluating the image quality of DDIM Guided with dataset CelebA.

We ran experiments for the BayesDiff and Hessian Free Laplacian approach. Additionally, we ran an Adversarial experiment with extreme parameters for the sigma noise and prior precision (0.001 and 1000, respectively), to see how the model would behave under extreme circumstances. 

The results of the Hessian-Free Laplacian approach indicate a lower FID score compared to both the normal BayesDiff variant and the adversarial BayesDiff variant across all aggregation methods (no aggregation, sum, and random selection). This indicates that the image quality produced by the Hessian-Free variant is superior to that generated by the Hessian approach. The differences in FID scores between the aggregation methods are minimal and do not indicate significant variations. However, it is noteworthy that the adversarial variant exhibits a higher FID score than the other two variants, suggesting poorer image quality.

Conversely, the CMMD scores for the Hessian-Free variant are slightly higher than those of the other two variants, which would typically suggest poorer image quality. However, this difference is very small, implying that replacing the Hessian or altering the hyperparameters does not result in significant differences. Across the aggregation methods, there is no notable difference in CMMD scores. Interestingly, unlike the FID evaluation, the adversarial variant yields the lowest CMMD scores, contradicting the trend of higher FID scores, suggesting no clear superiority in image quality based on CMMD scores alone.

Verschil in aggregation??
Note that this was tested on the CelebA dataset, providing less background or important regions in generated images, in contrast to ImageNet that contains more complex image compositions.

Final thoughts
In this blogpost we have reproduced the paper "BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference", that proposes a new Bayesian framework for pixel-wise uncertainty estimation. The authors claim that this estimated uncertainty can be used to identify and potentially discard the most uncertain images, or improve generated images by enhancing the diversity or rectifying artifacts in the generated samples. 

We have attempted to reproduce the results from the BayesDiff paper. However, we did not obtain the same results. Furthermore, we have extended the idea of the BayesDiff framework by testing the Bayesian approach, introducing CMMD, an additional metric, for assessing the quality of generated images, and experimenting with different aggregation methods for the uncertainty value per image.

We have found that the BayesDiff framework might not work as well as the authors present in their paper. Firstly, the uncertainty maps for ImageNet donâ€™t seem to be affected by changing hyperparameters which are valid for the LLLA, pointing to a problem in either the Bayesian method or its implementation. Secondly, we did not observe an improvement in image quality when filtering out low-quality images with the current aggregation method. This might suggest that the uncertainty predictions for images are not as meaningful as previously proposed. We have extended upon this issue by introducing two new aggregation methods, PatchMax and SegmentationMean. The alternate aggregation methods did not drastically change performance, either due to meaningless uncertainty or lesser added benefit through image composition.

Since BayesDiff can be computationally costly, we attempted to replace the Hessian with the diagonal of the prior precision. The Hessian-free variant demonstrated competitive CMMD scores and better FID scores compared to both the standard and extreme BayesDiffs. This suggests that the Hessian-free approach is a potentially preferable method for improving computational efficiency while maintaining or enhancing image quality.

Lastly, we want to press that the practical application of the BayesDiff framework might not work as expected. The authors introduce the BayesDiff framework as a way of filtering out low-quality images. However, images with a high uncertainty value are not necessarily of low quality. They merely exhibit more detail or more complex textures. Filtering these out will result in less diverse set of generations, which may not be desirable. 

Appendix

Hyperparameter tuning



Figure 5. Hyperparameter tuning of prior_precision between 0 and 1000 compared to the original settings with the DDPM model and ImageNet





Figure 6. Hyperparameter tuning of sigma_noise between 0 and 1 compared to the original settings with the DDPM model and ImageNet






Figure 7. Hyperparameter tuning of prior_precision between 0 and 1000 compared to the original settings with the DDPM model and CelebA





Figure 8. Hyperparameter tuning of sigma_noise between 0 and 1 compared to the original settings with the DDPM model and CelebA






Figure 9. Sample size motivation for the FID and CMMD. Left: absolute values of the metrics. Right: values relative to the value at 30k sample size.

Hessian Free Laplacian

Fig X: Uncertainty maps for CelebA in the Hessian free variant for different values of the prior precision.

Authors' Contributions
Literature review: Sebastiaan will be taking charge over the literature review. Although each member contributes to it.
Writing the general parts of the tutorial: Sebastiaan & Liang will be involved with the general sections of the tutorial, such as introduction, background, relevancy, etc.
Reproduce the findings: Jesse will work on reproducing the qualitative and quantitative results of the paper.
Hyperparameter tuning: Cile will be taking charge in tuning the hyperparameters of the Laplacian, therefore she will also write the part of the background, experiment setup, results, etc.
Replace the Hessian by KFAC & Making the Laplacian Hessian-Free: This is one of our extensions, Cile and Ivo will be looking into this part.
Implement a variant of the aggregation mechanism: Ivo will work on applying a variety of aggregation methods on the uncertainty estimates.
Replace the evaluation metrics: Liang will do further research on different metrics and will report results on replacing the FID with the CMMD.
Writing the tutorial will be divided amongst all members, since the tutorial is highly dependent on the execution of the code. Each member that engaged in a specific experiment will write that part of the tutorial.


References
[Barratt and Sharma, 2018] Barratt, S., & Sharma, R. (2018). A Note on the Inception Score. arXiv preprint arXiv:1801.01973
[Chen et al., 2014] Chen, T., Fox, E., & Guestrin, C. (2014). Stochastic Gradient Hamiltonian Monte Carlo. In Proceedings of the 31st International Conference on Machine Learning (pp. 1683-1691). PMLR. http://proceedings.mlr.press/v32/cheni14.pdf
[Chen et al., 2017] Chen, L. C., Papandreou, G., Schroff, F., & Adam, H. (2017). Rethinking atrous convolution for semantic image segmentation. arXiv preprint arXiv:1706.05587.
[Daxberger et al., 2022] Daxberger, E., Kristiadi, A., Immer, A., Eschenhagen, R., Bauer, M., & Hennig, P. (2022). Laplace Redux -- Effortless Bayesian Deep Learning. arXiv preprint arXiv:2106.14806. 
[Deng et al., 2009] Deng, J., Dong, W., Socher, R., Li, L. J., Li, K., & Fei-Fei, L. (2009, June). Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition (pp. 248-255). Ieee.
[Heusel et al., 2018] Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., & Hochreiter, S. (2018). GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium. arXiv preprint arXiv:1706.08500
[Ho et al., 2020] Ho, J., Jain, A., & Abbeel, P. (2020). Denoising Diffusion Probabilistic Models. arXiv preprint arXiv:2006.11239
[Jayasumana et al., 2024] Jayasumana, S., Ramalingam, S., Veit, A., Glasner, D., Chakrabarti, A., & Kumar, S. (2024). Rethinking FID: Towards a Better Evaluation Metric for Image Generation. arXiv preprint arXiv:2401.09603
[Kou et al., 2024] Kou, S., Gan, L., Wang, D., Li, C., & Deng, Z. (2024). BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference. arXiv preprint arXiv:2310.11142
[Kristiadi et al., 2020] Kristiadi, A., Hein, M., & Hennig, P. (2020). Being Bayesian, Even Just a Bit, Fixes Overconfidence in ReLU Networks. arXiv preprint arXiv:2002.10118.
[Liu et al., 2018] Liu, Z., Luo, P., Wang, X., & Tang, X. (2018). Large-scale celebfaces attributes (CelebA) dataset. Retrieved August, 15(2018), 11.
[McInerney and Kallus, 2024] McInerney, J., & Kallus, N. (2024). Hessian-Free Laplace in Bayesian Deep Learning. arXiv preprint arXiv:2403.10671
[Obukhov and Krasnyanskiy, 2020] Obukhov, A., & Krasnyanskiy, M. (2020). Quality assessment method for GAN based on modified metrics inception score and FrÃ©chet inception distance. In Software Engineering Perspectives in Intelligent Systems: Proceedings of 4th Computational Methods in Systems and Software 2020, Vol. 1 4 (pp. 102-114). Springer.
[Sauer et al., 2023] Sauer, A., Lorenz, D., Blattmann, A., & Rombach, R. (2023). Adversarial diffusion distillation. arXiv preprint arXiv:2311.17042
[Salimans et al., 2016] Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., & Chen, X. (2016). Improved Techniques for Training GANs. arXiv preprint arXiv:1606.03498
[Song et al., 2020] Song, J., Meng, C., & Ermon, S. (2022). Denoising Diffusion Implicit Models. arXiv preprint arXiv:2010.02502
[Wenzel et al., 2020] Wenzel, F., Roth, K., Veeling, B. S., ÅšwiÄ…tkowski, J., Tran, L., Mandt, S., Snoek, J., Jenatton, R., & Nowozin, S. (2020). How Good is the Bayes Posterior in Deep Neural Networks Really? arXiv preprint arXiv:2002.02405
[Yang et al., 2023] Yang, L., Zhang, Z., Song, Y., Hong, S., Xu, R., Zhao, Y., Zhang, W., Cui, B., & Yang, M.-H. (2023). Diffusion Models: A Comprehensive Survey of Methods and Applications. ACM Computing Surveys, 56(4), 105. https://doi.org/10.1145/3626235
[Zhdanov et al., 2023] Zhdanov, M., Dereka, S., & Kolesnikov, S. (2023). Unveiling Empirical Pathologies of Laplace Approximation for Uncertainty Estimation. arXiv preprint arXiv:2312.10464

