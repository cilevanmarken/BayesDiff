# Project proposal reproducibility & extension

## BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference

**Authors**: Brink, van Marken, Snel, Telkamp, Wiers

**Date**: April 2023

**Course**: Deep learning 2-course research proposal

### 1. Executive Summary

**Research problem**: The primary objective is to enhance the quality of images generated by diffusion models by incorporating pixel-wise uncertainty estimation through Bayesian inference. This involves reproducing the research of the paper "BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference" by Kou, Gan, Wang, Li, and Deng (2024) and suggesting methodology to improve their Bayesian inference implementation.

### 2. Survey of Background Literature

#### 2.1 Background

The paper 'BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference' by Kou et al. (2024) discusses the effectiveness of diffusion models (DMs) in transforming noise vectors into natural images across various applications, such as image synthesis and text-to-image generation. Despite their capabilities, these models often produce low-quality images, leading to a poor user experience. The paper highlights the challenge of filtering out these low-quality images due to the lack of a reliable metric for assessing image quality, with traditional evaluation metrics.

**Diffusion Models (DMs)**: Diffusion models are a family of probabilistic generative models that progressively destruct data by injecting noise, then learn to reverse this process for sample generation (Yang et al., 2023). First, a Denoising Diffusion Probabilistic Model (DDPM), which is the original diffusion approach, makes use of two Markov chains: a forward chain that perturbs data to noise, and a reverse chain that converts noise back to data. Building upon DDPMs, Song, Meng, and Ermon (2022) proposed a different approach namely, Denoising Diffusion Implicit Models (DDIMs). DDIMs provides a more efficient class of iterative implicit probabilistic models with the same training procedure.

**Laplacian & Hessian**: Bayesian approaches can be used for uncertainty quantification in Diffusion Models. One such Bayesian approach is Last Layer Laplace Approximation (LLLA), which can be applied to models post-hoc and is very cost-efficient. LLLA approximates the predictive posterior using a Gaussian distribution centered at a local maximum (θMAP) and a covariance matrix corresponding to the local curvature. This covariance matrix is computed by approximating the inverse of the Hessian. Using the variance of the predictive posterior, the pixel-wise uncertainty can be computed (Daxberger et al., 2022).

**Evaluating images**: The Frechet Inception Distance (FID) is a widely used evaluation metric for assessing the quality of generated images compared to real ones. It quantifies the dissimilarity between the distributions of features extracted from real images and those generated by an algorithm. However, recent research has highlighted limitations of FID, particularly its inconsistency with human perception in certain cases. For instance, FID may inaccurately assess image quality under progressive distortions, leading to misleading results (Jayasumana et al., 2024). The Inception Score (IS) measures variety in images and that each image distinctly looks like something. A higher IS means a better image quality. (Barratt & Sharma, 2018) The Inception Score has been used in the field of generative modeling as a benchmark for assessing the performance of GANs and related algorithms (Salimans et al., 2016).

#### 2.2 Relevance/Impact

Diffusion Models have shown to be capable of generating realistic samples across diverse domains, but are also prone to producing low-quality images. Evaluation metrics such as FID and Inception Scores are not perfect to evaluate generated images, since they fall short in capturing nuanced aspects of image quality. This inherent shortcoming prompts the search for more effective methods to enhance DMs, aiming to improve diversity and rectify artifacts in generated images. This paper tries to address these shortcomings by introducing pixel-wise uncertainty as a means to improve DMs. By incorporating uncertainty estimation, the model can identify and potentially discard the most uncertain images, or even improve generated images and enhancing diversity in the generated samples.

### 3. Proposed Methodology

The following steps are proposed for reproducing and possibly extending the paper.

**Hyperparameter tuning**: Firstly, we propose to do hyperparameter tuning on the LLLA. The code provided with the paper shows that the authors have fixed the parameters for the prior precision and the prior mean of the LLLA on 1 and 0, respectively. These two hyperparameters influence the behavior of the LLLA and should thus be fine-tuned. In the case that changing these hyperparameters doesn’t have a large impact on the resulting uncertainty maps, the question can be raised as to if a Bayesian approach to uncertainty in DMs is a good one.

**Approximating the Hessian**: A computational bottleneck of LLLA lies in computing the inverted Hessian. To make this computationally less heavy, the authors make use of diagonal factorization, ignoring all off-diagonal elements of the Hessian. However, diagonal approximations of the Hessian are outperformed significantly by the Kronecker-Factored Approximation Curvature (KFAC) approach, which offers greater expressiveness as mentioned by (Daxberger et al., 2022). As this might enhance the resulting uncertainty maps, we propose replacing diagonal factorization of the Hessian with KFAC factorization.

Additionally, (McInerney & Kallus, 2024) demonstrates that computing the Hessian might not even be necessary using the Hessian-free Laplace (HFL). Should the HFL lead to similar results as the LLLA, computing the pixel-wise uncertainty could be achieved with significantly less computation.

**Aggregation mechanism**: The availability of the uncertainty estimates per pixel in the generated images presents the need for an effective aggregation method. This method plays a significant role in deriving the final evaluation metric. The original paper suggests a sum across all pixel uncertainties. Nonetheless, this mere statistical interpretation might not fully capture the role different image regions play in assessing the realism of an image. Therefore, we suggest using a combination of weighted aggregation with segmentation maps, this might highlight uncertainties within primary objects and neglect uncertainties in complex and cluttered backgrounds. The segmentation maps may be derived through pre-trained models or simple downsampling operations such as pooling. Moreover, other statistical interpretations, such as variance and percentiles, might also be analyzed to see to what extent they describe the realism of images.

**Evaluation metric FID**: One of the most popular evaluation metrics for evaluating generated images is FID. FID estimates the distance between a distribution of features of real images, and those of images generated by some model. We want to utilize CMMD, which is not dependent on the sample size, as a more robust metric, suitable for evaluation of our generated images (Jayasumana et al., 2024).

### 4. Research Plan

#### 4.1 Plan

Our short-term objective is to reproduce the findings presented in the paper. Moving forward, in the long term, our focus will shift to hyperparameter tuning of the LLLA. If this tuning fails to significantly impact the uncertainty maps, the question can be raised if a Bayesian approach is valuable.

Based on these findings we can either 1) further refine the Bayesian approach by changing how the Hessian is approximated, which might lead to better uncertainty maps (KFAC ) or less computationally expensive uncertainty maps (HFL), or 2) explore non-Bayesian alternatives to generating uncertainty maps.

Additionally, we want to look into a new metric for image generation, CMMD, which might prove to be more informative than the metrics used in the paper.

Lastly, if there is time left, we would like to look into a new method of aggregation, to see if we can prevent the uncertainty metric from being less biased toward highly cluttered/complex backgrounds and focus more specifically on areas that tend to affect the realism of an image.

| Week        | Task                                                                                                    |
|-------------|---------------------------------------------------------------------------------------------------------|
| April 22-26 | Literature review and initial project setup.                                                            |
| May 6-10    | Present qualitative results (uncertainty maps); Discuss hyperparameter tuning findings.                 |
| May 13-17   | Laplacian: KFAC & Hessian-Free Laplacian; Bayesian: Aggregation mechanism; Evaluation metric: Rethinking FID; Try to reproduce uncertainty maps according to the timesteps. |
| May 19      | Deadline for draft report.                                                                              |
| May 20-24   | Review feedback on draft report (due by 22nd May).                                                      |
| May 27-31   | Finalize and submit the final report (due by 27th May); Prepare for poster presentation (due by 30th May).|

#### 4.2 Who does what?

- **Literature review**: Sebastiaan will be taking charge over the literature review, but every member contributes to it.
- **Writing the general parts of the tutorial**: Sebastiaan & Liang will be involved with the general sections of the tutorial, such as introduction, background, relevancy, etc.
- **Reproduce the findings**: Jesse will work on reproducing the qualitative and quantitative results of the paper.
- **Hyperparameter tuning**: Cile will be taking charge in tuning the hyperparameters of the Laplacian, therefore she will also write the part of the background, experiment setup
